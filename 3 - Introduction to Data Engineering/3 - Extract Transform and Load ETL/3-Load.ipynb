{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing to a file\n",
    "\n",
    "In the video, you saw that files are often loaded into a MPP database like Redshift in order to make it available for analysis.\n",
    "\n",
    "The typical workflow is to write the data into columnar data files. These data files are then uploaded to a storage system and from there, they can be copied into the data warehouse. In case of Amazon Redshift, the storage system would be S3, for example.\n",
    "\n",
    "The first step is to write a file to the right format. For this exercises you'll choose the Apache Parquet file format.\n",
    "\n",
    "There's a PySpark DataFrame called film_sdf and a pandas DataFrame called film_pdf in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the pandas DataFrame to parquet\n",
    "film_pdf.to_parquet(\"films_pdf.parquet\")\n",
    "\n",
    "# Write the PySpark DataFrame to parquet\n",
    "film_sdf.write.parquet(\"films_sdf.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load into Postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load into Postgres\n",
    "\n",
    "In this exercise, you'll write out some data to a PostgreSQL data warehouse. That could be useful when you have a result of some transformations, and you want to use it in an application.\n",
    "\n",
    "For example, the result of a transformation could have added a column with film recommendations, and you want to use them in your online store.\n",
    "\n",
    "There's a pandas DataFrame called film_pdf in your workspace.\n",
    "\n",
    "As a reminder, here's the structure of a connection URI for sqlalchemy:\n",
    "\n",
    "postgresql://[user[:password]@][host][:port][/database]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish the connection URI\n",
    "connection_uri = \"postgresql://repl:password@localhost:5432/dwh\"\n",
    "db_engine_dwh = sqlalchemy.create_engine(connection_uri)\n",
    "\n",
    "# Transformation step, join with recommendations data\n",
    "film_pdf_joined = film_pdf.join(recommendations)\n",
    "\n",
    "# Finish the .to_sql() call to write to store.film\n",
    "film_pdf_joined.to_sql(\"film\", db_engine_dwh, schema=\"store\", if_exists=\"replace\")\n",
    "\n",
    "# Run the query to fetch the data\n",
    "pd.read_sql(\"SELECT film_id, recommended_film_ids FROM store.film\", db_engine_dwh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
