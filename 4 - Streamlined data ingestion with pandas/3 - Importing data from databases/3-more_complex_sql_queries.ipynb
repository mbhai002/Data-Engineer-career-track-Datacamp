{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting distinct values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes an analysis doesn't need every record, but rather unique values in one or more columns. Duplicate values can be removed after loading data into a dataframe, but it can also be done at import with SQL's DISTINCT keyword.\n",
    "\n",
    "Since hpd311calls contains data about housing issues, we would expect most records to have a borough listed. Let's test this assumption by querying unique complaint_type/borough combinations.\n",
    "\n",
    "pandas has been imported as pd, and the database engine has been created as engine.\n",
    "\n",
    "Note: The SQL checker is quite picky about column positions and expects fields to be selected in the specified order.\n",
    "\n",
    "Instructions\n",
    "\n",
    "\n",
    "Create a query that gets DISTINCT values for borough and complaint_type (in that order) from hpd311calls.\n",
    "Use read_sql() to load the results of the query to a dataframe, issues_and_boros.\n",
    "Print the dataframe to check if the assumption that all issues besides literature requests appear with boroughs listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create query for unique combinations of borough and complaint_type\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT borough, \n",
    "       complaint_type\n",
    "  FROM hpd311calls;\n",
    "\"\"\"\n",
    "\n",
    "# Load results of query to a dataframe\n",
    "issues_and_boros = pd.read_sql(query, engine)\n",
    "\n",
    "# Check assumption about issues and boroughs\n",
    "print(issues_and_boros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting in groups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous exercises, you pulled data from tables, then summarized the resulting dataframes in pandas to create graphs. By using COUNT and GROUP BY in a SQL query, we can pull those summary figures from the database directly.\n",
    "\n",
    "The hpd311calls table has a column, complaint_type, that categorizes call records by issue, such as heating or plumbing. In order to graph call volumes by issue, you'll write a SQL query that COUNTs records by complaint type.\n",
    "\n",
    "pandas has been imported as pd, and the database engine for data.db has been created as engine.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Create a SQL query that gets the complaint_type column and counts of all records from hpd311calls, grouped by complaint_type.\n",
    "Create a dataframe with read_sql() of call counts by issue, calls_by_issue.\n",
    "Run the last section of code to graph the number of calls for each housing issue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create query to get call counts by complaint_type\n",
    "query = \"\"\"\n",
    "SELECT complaint_type, \n",
    "     COUNT(*)\n",
    "  FROM hpd311calls\n",
    "  GROUP BY complaint_type;\n",
    "\"\"\"\n",
    "\n",
    "# Create dataframe of call counts by issue\n",
    "calls_by_issue = pd.read_sql(query, engine)\n",
    "\n",
    "# Graph the number of calls for each housing issue\n",
    "calls_by_issue.plot.barh(x=\"complaint_type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Working with aggregate functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a table contains data with higher granularity than is needed for an analysis, it can make sense to summarize the data with SQL aggregate functions before importing it. For example, if you have data of flood event counts by month but precipitation data by day, you may decide to SUM precipitation by month.\n",
    "\n",
    "The weather table contains daily readings for four months. In this exercise, you'll practice summarizing weather by month with the MAX, MIN, and SUM functions.\n",
    "\n",
    "pandas has been loaded as pd, and a database engine, engine, has been created.\n",
    "\n",
    "Instructions 1/3\n",
    "\n",
    "Create a query to pass to read_sql() that will get months and the MAX value of tmax by monthfrom weather.\n",
    "\n",
    "Modify the query to also get the MIN tmin value for each month.\n",
    "\n",
    "Modify the query to also get the total precipitation (prcp) for each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a query to get month and max tmax by month\n",
    "query = \"\"\"\n",
    "SELECT month , \n",
    "       MAX(tmax)\n",
    "  FROM weather \n",
    "  GROUP BY  month;\"\"\"\n",
    "\n",
    "# Get dataframe of monthly weather stats\n",
    "weather_by_month = pd.read_sql(query, engine)\n",
    "\n",
    "# View weather stats by month\n",
    "print(weather_by_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a query to get month, max tmax, and min tmin by month\n",
    "query = \"\"\"\n",
    "SELECT month, \n",
    "\t   MAX(tmax), \n",
    "       MIN(tmin)\n",
    "  FROM weather \n",
    " GROUP BY month;\n",
    "\"\"\"\n",
    "\n",
    "# Get dataframe of monthly weather stats\n",
    "weather_by_month = pd.read_sql(query, engine)\n",
    "\n",
    "# View weather stats by month\n",
    "print(weather_by_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create query to get temperature and precipitation by month\n",
    "query = \"\"\"\n",
    "SELECT month, \n",
    "        MAX(tmax), \n",
    "        MIN(tmin),\n",
    "        sum(prcp)\n",
    "  FROM weather \n",
    " GROUP BY month;\n",
    "\"\"\"\n",
    "\n",
    "# Get dataframe of monthly weather stats\n",
    "weather_by_month = pd.read_sql(query, engine)\n",
    "\n",
    "# View weather stats by month\n",
    "print(weather_by_month)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
