{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import a subset of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Vermont tax data contains 147 columns describing household composition, income sources, and taxes paid by ZIP code and income group. Most analyses don't need all these columns. In this exercise, you will create a dataframe with fewer variables using read_csv()s usecols argument.\n",
    "\n",
    "Let's focus on household composition to see if there are differences by geography and income level. To do this, we'll need columns on income group, ZIP code, tax return filing status (e.g., single or married), and dependents. The data uses codes for variable names, so the specific columns needed are in the instructions.\n",
    "\n",
    "pandas has already been imported as pd.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Create a list of columns to use: zipcode, agi_stub (income group), mars1 (number of single households), MARS2 (number of households filing as married), and NUMDEP (number of dependents).\n",
    "Create a dataframe from vt_tax_data_2016.csv that uses only the selected columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzipcode\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124magi_stub\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmars1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMARS2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNUMDEP\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Create dataframe from csv using only selected columns\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvt_tax_data_2016.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, usecols \u001b[38;5;241m=\u001b[39m cols)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# View counts of dependents and tax returns by income level\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magi_stub\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msum())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# code\n",
    "\n",
    "# Create list of columns to use\n",
    "cols = ['zipcode', 'agi_stub', 'mars1', 'MARS2', 'NUMDEP']\n",
    "\n",
    "# Create dataframe from csv using only selected columns\n",
    "data = pd.read_csv(\"vt_tax_data_2016.csv\", usecols = cols)\n",
    "\n",
    "# View counts of dependents and tax returns by income level\n",
    "print(data.groupby(\"agi_stub\").sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import a file in chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with large files, it can be easier to load and process the data in pieces. Let's practice this workflow on the Vermont tax data.\n",
    "\n",
    "The first 500 rows have been loaded as vt_data_first500. You'll get the next 500 rows. To do this, you'll employ several keyword arguments: nrows and skiprows to get the correct records, header to tell pandas the data does not have column names, and names to supply the missing column names. You'll also want to use the list() function to get column names from vt_data_first500 to reuse.\n",
    "\n",
    "pandas has been imported as pd.\n",
    "\n",
    "Instructions\n",
    "\n",
    "Use nrows and skiprows to make a dataframe, vt_data_next500, with the next 500 rows.\n",
    "Set the header argument so that pandas knows there is no header row.\n",
    "Name the columns in vt_data_next500 by supplying a list of vt_data_first500's columns to the names argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code\n",
    "\n",
    "# Create dataframe of next 500 rows with labeled columns\n",
    "vt_data_next500 = pd.read_csv(\"vt_tax_data_2016.csv\", \n",
    "                       \t\t  nrows = 500,\n",
    "                       \t\t  skiprows = 500,\n",
    "                       \t\t  header = None,\n",
    "                       \t\t  names = list(vt_data_first500))\n",
    "\n",
    "# View the Vermont dataframes to confirm they're different\n",
    "print(vt_data_first500.head())\n",
    "print(vt_data_next500.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
